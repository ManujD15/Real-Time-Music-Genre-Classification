{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "uhDPFEatEv-S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import h5py\n",
        "import librosa\n",
        "import itertools\n",
        "from copy import copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import OrderedDict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xQ8Ga9wNEv-n"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model,load_model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Add\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import PReLU\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "colab_type": "code",
        "id": "kVVdJwV1FgJf",
        "outputId": "26d36384-d2b0-4e10-ce75-15d2a3f81cc6"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "MsL1_E70Fsfx",
        "outputId": "e25fcde7-27a9-4bd5-b46c-dba9e2d294ac"
      },
      "outputs": [],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9p_2-STWGho1"
      },
      "source": [
        "After Mounting Drive, Change Current Working Directory to \n",
        "**PATH** : '/content/drive/My Drive/Audio Classification with DL'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ZvOUoiMZGw31"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"C:\\\\Users\\\\manuj\\\\OneDrive\\\\Desktop\\\\FData\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MAoOnlJaEv-5"
      },
      "outputs": [],
      "source": [
        "# For reproducibility purposes\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qjUGwRcZEv_F"
      },
      "source": [
        "# Read the data\n",
        "\n",
        "> Helper functions to assist the process to read songs, split then and return an array of spectrograms/melspectrograms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "UFZ_6QOPEv_I"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "@description: Method to split a song into multiple songs using overlapping windows\n",
        "\"\"\"\n",
        "def songsplit(X, y, window = 0.05, overlap = 0.5):\n",
        "    # Empty lists to hold our results\n",
        "    temp_X = []\n",
        "    temp_y = []\n",
        "\n",
        "    # Get the input song array size\n",
        "    xshape = X.shape[0]\n",
        "    chunk = int(xshape*window)\n",
        "    offset = int(chunk*(1.-overlap))\n",
        "    \n",
        "    # Split the song and create new ones on windows\n",
        "    spsong = [X[i:i+chunk] for i in range(0, xshape - chunk + offset, offset)]\n",
        "    for s in spsong:\n",
        "        if s.shape[0] != chunk:\n",
        "            continue\n",
        "\n",
        "        temp_X.append(s)\n",
        "        temp_y.append(y)\n",
        "\n",
        "    return np.array(temp_X), np.array(temp_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YSiFtUaCEv_T"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "@description: Method to convert a list of songs to a np array of melspectrograms\n",
        "\"\"\"\n",
        "def melspectrogram(songs, n_fft=1024, hop_length=256):\n",
        "    # Transformation function\n",
        "    melspec = lambda x: librosa.feature.melspectrogram(x, n_fft=n_fft,\n",
        "        hop_length=hop_length, n_mels=128)[:,:,np.newaxis] #keep n_mels=128. other values are for experimenting\n",
        "\n",
        "    # map transformation of input songs to melspectrogram using log-scale\n",
        "    tsongs = map(melspec, songs)\n",
        "    # np.array([librosa.power_to_db(s, ref=np.max) for s in list(tsongs)])\n",
        "    return np.array(list(tsongs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ZEbHw5ahEv_f"
      },
      "outputs": [],
      "source": [
        "def convert_split(X, y,song_samples=660000):\n",
        "    arr_spec, arr_genre = [], []\n",
        "    \n",
        "    # Convert to spectrograms and split into small windows\n",
        "    for fn, genre in tqdm(zip(X, y),total=len(y),desc='Processing Audio Files'):\n",
        "        signal, sr = librosa.load(fn)\n",
        "        signal = signal[:song_samples]\n",
        "\n",
        "        # Convert to dataset of spectograms/melspectograms\n",
        "        signals, y = songsplit(signal, genre, window=0.05) #keep window=0.05. Other values are for experimenting. \n",
        "\n",
        "        # Convert to \"spec\" representation\n",
        "        specs = melspectrogram(signals)\n",
        "\n",
        "        # Save files\n",
        "        arr_genre.extend(y)\n",
        "        arr_spec.extend(specs)\n",
        "    \n",
        "    return np.array(arr_spec), to_categorical(arr_genre)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "qswtYBx0Ev_o"
      },
      "outputs": [],
      "source": [
        "def read_dataset(src_dir, genres, song_samples,get_data='train'):    \n",
        "    # Empty array of dicts with the processed features from all files\n",
        "    arr_fn = []\n",
        "    arr_genres = []\n",
        "\n",
        "    # Get file list from the folders\n",
        "    if get_data=='train':\n",
        "        for x,_ in genres.items():\n",
        "            folder = src_dir+'/'+'Train'+'/' + x\n",
        "            # print(folder)\n",
        "            for root, subdirs, files in os.walk(folder):\n",
        "                # print(f\"root = {root}\\n subdirs = {subdirs} \\n files = {files}\")\n",
        "                for file in files:\n",
        "                    file_name = folder + \"/\" + file\n",
        "                    # print(f\"filename = {file_name}\")\n",
        "                    # Save the file name and the genre\n",
        "                    arr_fn.append(file_name)\n",
        "                    arr_genres.append(genres[x])\n",
        "        \n",
        "        # Split into small segments and convert to spectrogram\n",
        "        X_train, y_train = convert_split(arr_fn, arr_genres)\n",
        "        return X_train, y_train\n",
        "    \n",
        "    elif get_data=='test':\n",
        "        for x,_ in genres.items():\n",
        "            folder = src_dir+'/'+'Test'+'/' + x\n",
        "            # print(folder)\n",
        "            for root, subdirs, files in os.walk(folder):\n",
        "                # print(f\"root = {root}\\n subdirs = {subdirs} \\n files = {files}\")\n",
        "                for file in files:\n",
        "                    file_name = folder + \"/\" + file\n",
        "                    # print(f\"filename = {file_name}\")\n",
        "                    # Save the file name and the genre\n",
        "                    arr_fn.append(file_name)\n",
        "                    arr_genres.append(genres[x])\n",
        "        \n",
        "        # Split into small segments and convert to spectrogram\n",
        "        X_test, y_test = convert_split(arr_fn, arr_genres)\n",
        "        return X_test, y_test\n",
        "    \n",
        "    # elif get_data=='test':\n",
        "    #     folder = src_dir+'/'+'Test'\n",
        "    #     for root, subdirs, files in os.walk(folder):\n",
        "    #         print(f\"root = {root} \\n subdirs = {subdirs} \\n files = {files}\")\n",
        "    #         for idx,file in enumerate(files):\n",
        "    #             file_name = folder + \"/\" + file\n",
        "    #             print(file_name)\n",
        "    #             print(idx)\n",
        "    #             # Save the file name and the genre\n",
        "    #             arr_fn.append(file_name)\n",
        "    #             arr_genres.append(idx//10)\n",
        "    \n",
        "    #     X_test, y_test = split_convert(arr_fn, arr_genres)\n",
        "    #     return X_test, y_test\n",
        "    else:\n",
        "        #print('Specify \"test\" or \"train\"')\n",
        "        return None,None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "Z3SrilZtEv_w",
        "outputId": "50c580c0-b1cb-4106-ff6a-1022eeae3deb"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "gtzan_dir = 'FData'\n",
        "song_samples = 660000\n",
        "genres = {'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4, \n",
        "          'jazz': 5, 'metal': 6, 'pop': 7, 'reggae': 8, 'rock': 9}\n",
        "\n",
        "# Read the data\n",
        "X_train, y_train = read_dataset(gtzan_dir, genres, song_samples,get_data='train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test, y_test = read_dataset(gtzan_dir, genres, song_samples,get_data='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "YDkVi3_9Ev_8",
        "outputId": "497a1c02-d3df-45a8-8631-7f0346d196ba"
      },
      "outputs": [],
      "source": [
        "#print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "colab_type": "code",
        "id": "O9Nqtp8wEwAF",
        "outputId": "6fb51f9a-9c42-49ac-c80c-1d404073cf70"
      },
      "outputs": [],
      "source": [
        " # Histogram for train and test \n",
        "values, count = np.unique(np.argmax(y_train, axis=1), return_counts=True)\n",
        "plt.bar(values, count)\n",
        "\n",
        "values, count = np.unique(np.argmax(y_test, axis=1), return_counts=True)\n",
        "plt.bar(values, count)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PLwUvGRnEwAR"
      },
      "source": [
        "# GTZAN Melspectrogram Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gzpydk2mEwAV"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class GTZANGenerator(Sequence):\n",
        "    def __init__(self, X, y, batch_size=64, is_test = False):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.batch_size = batch_size\n",
        "        self.is_test = is_test\n",
        "    \n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.X)/self.batch_size))\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        # Get batch indexes\n",
        "        signals = self.X[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Apply data augmentation\n",
        "        if not self.is_test:\n",
        "            signals = self.__augment(signals)\n",
        "        return signals, self.y[index*self.batch_size:(index+1)*self.batch_size]\n",
        "    \n",
        "    def __augment(self, signals, hor_flip = 0.5, random_cutout = 0.5):\n",
        "        spectrograms =  []\n",
        "        for s in signals:\n",
        "            signal = copy(s)\n",
        "            \n",
        "            # Perform horizontal flip\n",
        "            if np.random.rand() < hor_flip:\n",
        "                signal = np.flip(signal, 1)\n",
        "\n",
        "            # Perform random cutoout of some frequency/time\n",
        "            if np.random.rand() < random_cutout:\n",
        "                lines = np.random.randint(signal.shape[0], size=2)\n",
        "                cols = np.random.randint(signal.shape[0], size=3)\n",
        "                signal[lines, :, :] = -80 # dB\n",
        "                signal[:, cols, :] = -80 # dB\n",
        "\n",
        "            spectrograms.append(signal)\n",
        "        return np.array(spectrograms)\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.X))\n",
        "        np.random.shuffle(self.indexes)\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5Jkz1Z0XEwAe"
      },
      "source": [
        "# Custom CNN (Melspectrogram version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FdFm1rCGEwAh"
      },
      "outputs": [],
      "source": [
        "def block_conv(x, n_filters,filter_size=(3, 3), pool_size=(2, 2),stride=(1, 1)):\n",
        "    x = Conv2D(n_filters, filter_size, strides=(1, 1), padding='same')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D(pool_size=pool_size, strides=stride)(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "vSUqInqvEwAr"
      },
      "outputs": [],
      "source": [
        "# Model Definition\n",
        "def make_model(input_shape, num_genres):\n",
        "    inpt = Input(shape=input_shape)\n",
        "    x = block_conv(inpt, 16,stride=(2,2))\n",
        "    x = block_conv(x, 32,filter_size=(3,3),stride=(2,2))\n",
        "    x = block_conv(x, 64, stride=(2,2))\n",
        "    x = block_conv(x, 128,filter_size=(3,3),stride=(2,2))\n",
        "    x = block_conv(x, 256,stride=(2,2))\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(128, activation='relu', \n",
        "              kernel_regularizer=tensorflow.keras.regularizers.l2(0.01))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    predictions = Dense(num_genres, \n",
        "                        activation='softmax', \n",
        "                        kernel_regularizer=tensorflow.keras.regularizers.l2(0.01))(x)\n",
        "    \n",
        "    model = Model(inputs=inpt, outputs=predictions)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IlEU-rAvEwAy"
      },
      "outputs": [],
      "source": [
        "model = make_model(X_train[0].shape, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "PTcfKbOyEwA8",
        "outputId": "5924b82a-e85c-4bda-de06-ec52fda924d3"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fbn_9cwvEwBC"
      },
      "source": [
        "### Loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gIOmwWwxEwBF"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=tensorflow.keras.losses.categorical_crossentropy,\n",
        "              optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IgXaQ8gkEwBN"
      },
      "outputs": [],
      "source": [
        "reduceLROnPlat = ReduceLROnPlateau(\n",
        "    monitor='val_loss', \n",
        "    factor=0.97,\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    mode='min',\n",
        "    min_delta=0.0001,\n",
        "    cooldown=2,\n",
        "    min_lr=1e-10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "PJBdoW3nEwBW"
      },
      "outputs": [],
      "source": [
        "# Generators\n",
        "batch_size = 128\n",
        "train_generator = GTZANGenerator(X_train, y_train)\n",
        "steps_per_epoch = np.ceil(len(X_train)/batch_size)\n",
        "\n",
        "validation_generator = GTZANGenerator(X_test, y_test)\n",
        "val_steps = np.ceil(len(X_test)/batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "9sdywKhhEwBe",
        "outputId": "ae0fb623-255b-443d-e1f5-3d60d92a83c5",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "hist = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=val_steps,\n",
        "    epochs=500,\n",
        "    verbose=1,\n",
        "    callbacks=[reduceLROnPlat])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "hQ3jCSpnEwBm",
        "outputId": "db117e8e-c9f6-43cd-9d43-a5ffc427aa25"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"val_loss = {:.3f} and val_acc = {:.3f}\".format(score[0], score[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "colab_type": "code",
        "id": "nXQM2oVYEwBu",
        "outputId": "4c098a3e-21d7-450e-f47b-c74dfcd57fa9"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(hist.history['accuracy'], label='train')\n",
        "plt.plot(hist.history['val_accuracy'], label='validation')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(hist.history['loss'], label='train')\n",
        "plt.plot(hist.history['val_loss'], label='validation')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "VuK7xc5jEwB3"
      },
      "outputs": [],
      "source": [
        "#http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "def plt_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "S3iwP8j2EwB_"
      },
      "outputs": [],
      "source": [
        "preds = np.argmax(model.predict(X_test), axis = 1)\n",
        "y_orig = np.argmax(y_test, axis = 1)\n",
        "cm = confusion_matrix(preds, y_orig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "colab_type": "code",
        "id": "_O4n4UQ4EwCF",
        "outputId": "f4119266-32e5-40fc-d0c9-4fabc65d334e"
      },
      "outputs": [],
      "source": [
        "keys = OrderedDict(sorted(genres.items(), key=lambda t: t[1])).keys()\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt_confusion_matrix(cm, keys, normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Bs4aA9d3EwCL"
      },
      "source": [
        "## Majority Vote\n",
        "### This is to decide which label is predicted by model, we collect probability score from each output neuron and then decide where the majority voting is going to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "h9Qdm9PeEwCN"
      },
      "outputs": [],
      "source": [
        "def maj_vote(scores):\n",
        "    values, counts = np.unique(scores,return_counts=True)\n",
        "    ind = np.argmax(counts)\n",
        "    return values[ind]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading a trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loaded_model = load_model(\"models\\manuj_cnn_2.h5\")\n",
        "loaded_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "byLQXCchEwCT"
      },
      "outputs": [],
      "source": [
        "preds = model.predict(X_test, batch_size=128, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "uHdGKwtmEwCZ"
      },
      "outputs": [],
      "source": [
        "# Each sound was divided into 39 segments in our custom function\n",
        "scores_songs = np.split(np.argmax(preds, axis=1), 300)\n",
        "scores_songs = [maj_vote(scores) for scores in scores_songs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "vxSRuTS1EwCi"
      },
      "outputs": [],
      "source": [
        "# Same analysis for split\n",
        "label = np.split(np.argmax(y_test, axis=1), 300)\n",
        "label = [maj_vote(l) for l in label]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "1WSad67DEwCq",
        "outputId": "d684f23c-022d-474b-c544-99ef2df3bbdc"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"majority voting system (acc) = {:.3f}\".format(accuracy_score(label, scores_songs)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u7iAJBg2EwCw"
      },
      "source": [
        "Compared to the classical approach, we are winning now!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ihmnNpICEwCw"
      },
      "source": [
        "## Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BMqEgpiUEwC0"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model.save('manuj_cnn.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "CNN_train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
